{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\python312\\lib\\site-packages (1.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.84.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\python312\\lib\\site-packages (from openai) (0.10.0)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: annotated-types, pydantic, openai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Python312\\Lib\\site-packages)\n",
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'C:\\\\Python312\\\\Scripts\\\\openai.exe' -> 'C:\\\\Python312\\\\Scripts\\\\openai.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API keys stored in .env file. Use load_dotenv() to read the file and inject any KEY=VALUE pairs into os.environ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the API keys into environment variables\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# load_dotenv() looks for a file named .env in the current working \n",
    "# directory (or parent directories) and, if found, reads lines like:\n",
    "\n",
    "# OPENAI_API_KEY = sk-…some-secret-string…\n",
    "# OTHER_SECRET = abc123\n",
    "\n",
    "# and then does essentially:\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-…some-secret-string…\"\n",
    "# for each line.\n",
    "\n",
    "# The argument override=True means: if os.environ already has a \n",
    "# key named OPENAI_API_KEY, overwrite it with whatever’s in .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists\n"
     ]
    }
   ],
   "source": [
    "# Check the keys\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the OpenAI class\n",
    "\n",
    "openAIObject = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messagesToLLM = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n",
    "\n",
    "# builds a list of message objects in the format expected by OpenAI’s ChatCompletion API\n",
    "\n",
    "# LLMs expect a list of message objects / dictionaries, each with a role and content.\n",
    "\n",
    "# role = \"user\" always means that this is text coming from the end user.\n",
    "\n",
    "# content = \"Something here\" is just a placeholder string for whatever prompt you want to send."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "response = openAIObject.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messagesToLLM\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If three typists can type three pages in three minutes, how many typists will it take to type 18 pages in six minutes?\n"
     ]
    }
   ],
   "source": [
    "response = openAIObject.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "# Now we have a question generated by the LLM\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step-by-step.\n",
      "\n",
      "**Given:**\n",
      "\n",
      "- 3 typists can type 3 pages in 3 minutes.\n",
      "\n",
      "**Goal:**\n",
      "\n",
      "- Find how many typists are needed to type 18 pages in 6 minutes.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Find the rate per typist\n",
      "\n",
      "From the given data:\n",
      "\n",
      "- 3 typists type 3 pages in 3 minutes.\n",
      "\n",
      "So,\n",
      "\n",
      "- Total pages per minute by 3 typists = 3 pages / 3 minutes = 1 page/minute.\n",
      "\n",
      "Therefore,\n",
      "\n",
      "- Pages per minute per typist = (1 page/minute) / 3 typists = 1/3 page per minute per typist.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Find required total typing rate for the new goal\n",
      "\n",
      "We want to type 18 pages in 6 minutes.\n",
      "\n",
      "- Required pages per minute = 18 pages / 6 minutes = 3 pages/minute.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Find how many typists (let's say \\( n \\)) are needed at the rate 1/3 page per minute each to achieve 3 pages/minute total.\n",
      "\n",
      "Total rate = \\( n \\times \\frac{1}{3} \\) pages/minute.\n",
      "\n",
      "Set equal to required rate:\n",
      "\n",
      "\\[\n",
      "n \\times \\frac{1}{3} = 3\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "n = 3 \\times 3 = 9\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{9}\n",
      "\\]\n",
      "\n",
      "**So, 9 typists are needed to type 18 pages in 6 minutes.**\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openAIObject.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One promising business area to explore for an Agentic AI opportunity is **Personalized Healthcare Management**.\n",
      "\n",
      "### Why Personalized Healthcare Management?\n",
      "\n",
      "1. **Complex Decision-Making Needs:** Managing chronic diseases, medication schedules, lifestyle changes, and regular health monitoring involves complex, ongoing decisions. An agentic AI can autonomously analyze patient data, adapt recommendations in real-time, and coordinate with healthcare providers.\n",
      "\n",
      "2. **Data Integration:** Patients generate diverse data streams—wearables, electronic health records, lab results. An agentic AI can synthesize these inputs to provide coherent, actionable health plans.\n",
      "\n",
      "3. **Proactive Interventions:** Rather than passive monitoring, agentic AI can proactively suggest interventions, schedule appointments, or alert healthcare professionals to potential issues before they become critical.\n",
      "\n",
      "4. **Scalability:** With growing healthcare demands and limited personnel, automating personalized care management enhances reach while maintaining quality.\n",
      "\n",
      "### Potential Applications\n",
      "- Automated chronic disease management assistant (e.g., diabetes or heart conditions).\n",
      "- Mental health monitoring and adaptive therapy recommendations.\n",
      "- Post-operative care and rehabilitation coaching.\n",
      "- Medication adherence and interaction management.\n",
      "\n",
      "This area combines societal value with a strong business case, leveraging agentic AI’s autonomous decision-making and adaptability to improve outcomes and reduce costs.\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"pick a business area that might be worth exploring for an Agentic AI opportunity\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openAIObject.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "\n",
    "print(business_idea)\n",
    "\n",
    "# And repeat!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
